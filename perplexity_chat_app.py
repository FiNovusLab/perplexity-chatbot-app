"""
Perplexity Sonar AI ì±—ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜
Perplexity APIë¥¼ í™œìš©í•œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ì˜ AI ì±—ë´‡ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤.
"""

import os
import streamlit as st
from dotenv import load_dotenv

# ëª¨ë“ˆ ì„í¬íŠ¸
from modules.api_client import PerplexityClient, process_stream_response, display_metadata
from modules.file_processor import create_file_attachment_message
from modules.ui_components import (
    setup_page, initialize_session_state, render_sidebar,
    render_file_upload_section, render_chat_history, render_cancel_button
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Perplexity API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("PERPLEXITY_API_KEY")
if not api_key:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— PERPLEXITY_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    st.stop()

# Perplexity API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
perplexity_client = PerplexityClient(api_key)

# í˜ì´ì§€ ì„¤ì •
setup_page()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
initialize_session_state()

# ì‚¬ì´ë“œë°” ë Œë”ë§
settings = render_sidebar()
model = settings["model"]
temperature = settings["temperature"]
max_tokens = settings["max_tokens"]
system_message = settings["system_message"]

# ë©”ì¸ í™”ë©´ ì œëª©
st.title("Perplexity AI ì±—ë´‡ ğŸ¤–")

# íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ë Œë”ë§
render_file_upload_section()

# ì±„íŒ… ê¸°ë¡ ë Œë”ë§
render_chat_history()

# ì‘ë‹µ ìƒì„± ì·¨ì†Œ ë²„íŠ¼ ë Œë”ë§
render_cancel_button()

# ì‚¬ìš©ì ì…ë ¥
prompt = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", disabled=st.session_state.generating)

# ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ
if prompt:
    content = prompt

    # íŒŒì¼ ì²¨ë¶€ ë©”ì‹œì§€ ìƒì„±
    file_message = create_file_attachment_message(st.session_state.uploaded_files)
    if file_message:
        #file_prompt = {"type": "image_url", "image_url": file_message}
        content = [{"type": "text", "text": prompt}] + file_message

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": content})
    with st.chat_message("user"):
        st.write(prompt)

    # ìƒì„± ìƒíƒœ ì„¤ì •
    st.session_state.generating = True
    st.session_state.cancel_generation = False

    # AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()

        # ë©”ì‹œì§€ ì¤€ë¹„
        messages = [{"role": "system", "content": system_message}]
        messages.extend([
            {"role": m["role"], "content": m["content"]}
            for m in st.session_state.messages
        ])

        # MCP ì„œë²„ ì„¤ì •
        mcp_servers = []
        for server in st.session_state.mcp_servers:
            mcp_servers.append({"url": server})

        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        try:
            # print(f"{messages}\n\n")
            # ì‘ë‹µ ìƒì„±
            stream = perplexity_client.generate_stream_response(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                use_mcp=st.session_state.enable_mcp,
                mcp_servers=mcp_servers if mcp_servers else None
            )

            # ì‘ë‹µ ì²˜ë¦¬ ë° í‘œì‹œ
            full_response, metadata = process_stream_response(
                stream,
                message_placeholder,
                lambda: st.session_state.cancel_generation
            )

            # ë©”íƒ€ë°ì´í„° í‘œì‹œ
            display_metadata(metadata)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            raise e

    # ìƒì„± ìƒíƒœ í•´ì œ
    st.session_state.generating = False
    st.session_state.cancel_generation = False

    # AI ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    if full_response:  # ì·¨ì†Œëœ ê²½ìš° ë¹ˆ ì‘ë‹µì´ ë  ìˆ˜ ìˆìŒ
        st.session_state.messages.append({"role": "assistant", "content": full_response})

    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
    # st.rerun()

# í‘¸í„°
st.markdown("---")
st.markdown("Powered by Perplexity Sonar API")
